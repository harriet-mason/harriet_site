---
title: "Uncertainty Literature Review"
author: Harriet Mason
bibliography: references.bib
date: last-modified
format: pdf
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
#| warning: false
#| message: false

# Load libraries
library(tidyverse)
library(tsibbledata)
library(Vizumap)
library(fable)
```


# The purpose of visualisation
The purpose of visualistion is insight. If we one cared about the accuracy of a value, a table would a better method of communicating the information [@Cleveland1984]. Data visualisation is commonly utilised as a tool in data exploration, so it is not uncommon for a data analyst to make a plot with only a vague goal and pull out a large number of adjacent observations.

Think back to the last time you made some sort of data visualisation. What was the purpose of that visualisation? Was it to better understand your data? Was it to help you make a decision? Was it to to communicate that decision to someone else? Now think about the last time you expressed some form of uncertainty. Was it a set of numerical confidence intervals? Maybe they were expressed as a set of values in a table. Did you consider visualising your uncertainty instead? There are many stages in our analysis that benefit from the power of data visualisation, however this does not mean it is always done with success. Visualization is an important step in exploratory data analysis and it is often utilised to **learn** what is important about a data set. The importance of data driven discovery is highlighted by data sets such as Anscombe's quartet [@anscombe] or the Datasaurus Dozen [@datasaurpkg]. Each of the pairwise plots in these data sets have the same summary statistics but strikingly different information when visualised. Anscombe quartet is shown in @fig-anscombe, because describing the data is never the same as seeing it. Instead of having to repeatedly check endless hypothesis to find interesting numerical features, visualisations **tell** us what is important about our data. This powerful aspect of data visualisation is poorly or seldom used in later stages when we are communicating our findings, specifically with respect to uncertainty. 

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-anscombe
#| fig-cap: "The four scatter plots that make up Anscombe's quartet. The four scatter plots are visually distinct but have the same mean, standard deviation, and correlation. The visualisation highlights the importance of plotting your data to identify interesting features that are hidden by other summary statistics."
tibble(x = c(anscombe$x1, anscombe$x2,
             anscombe$x3, anscombe$x4),
       y = c(anscombe$y1, anscombe$y2,
             anscombe$y3, anscombe$y4),
       Plot = c(rep("Plot 1",11), rep("Plot 2",11), 
                rep("Plot 3",11), rep("Plot 4",11))) %>%
  ggplot(aes(x,y)) +
  geom_point(aes(fill=Plot), colour="black", 
             size=3, pch=21, alpha=0.75) +
  facet_wrap(~Plot) +
  theme_classic() +
  theme(aspect.ratio = 1,
        legend.position = "none") +
  scale_fill_brewer(type = "qual", palette = 4)
```

Visualisations can provide a more complete picture of a risk than numerical summaries alone. Even something as simple as sketching a distribution before recalling statistics or making predictions can greatly increase the accuracy of those measures [@Hullman2018; @Goldstein2014]. While there is some evidence that confidence intervals provided in text form only are less likely to be misinterpreted than graphics [@Savelli2013], text is insufficient to express more complicated aspects of a distribution, such as mass. Expressing uncertainty verbally decreases the perceived reliability and trustworthiness of the source [@VanderBles2020]. Any confusion caused by expressing uncertainty as a visualisation could also be due to a lack of exposure, since @Kay2016 found people repeatedly exposed to the same uncertainty visualisations quickly get better at making judgements. Additionally, visualisation allow for interactive graphics that provide a more in depth understanding of probability [@Potter2009; @Ancker2009] and infographics that make uncertainty more accessible for people with poor numeracy skills [@Ancker2009]. 

Despite these benefits, there is evidence that we don't visualise uncertainty as often as we should. A survey conducted by @Hullman2020a found that majority of visualisation authors agreed that expressing uncertainty is important and should be done more often than it currently is, some even agreed that failing to do so is tantamount to fraud. Despite this, only a quarter of respondents included uncertainty in 50% or more of their visualisations [@Hullman2020a]. Meaning participants were convinced that visualising uncertainty is morally important but were able to provide self sufficient reasoning that allows them to avoid doing it. Some economists suggest that visualisation authors are responding to incentives that make it tempting to avoid visualising uncertainty, even if those incentives are based more in perception than reality [@Manski2020]. The study by @Hullman2020a found that the most common reasons authors don't visualise uncertainty despite knowing it's moral importance are: not wanting to overwhelm the audience; an inability to calculate the uncertainty; a lack of access to the uncertainty information; and not wanting to make their data seem questionable [@Hullman2020a].

If decision markers are not presented with the uncertainty about an estimate the data analysts have, for all intents and purposes, made the decision for the decision maker. Upon further interviews @Hullman2020a found that authors believed uncertainty would overwhelm the audience and make their data seem questionable because decision makers are unable to understand uncertainty. This belief, while pervasive, is not true. There is some research that suggests laypeople cannot understand complicated concepts in statistical thinking (such as trick questions on hypothesis tests or the difference between Frequentist and Bayesian thinking) [@Hoekstra2014; @Bella2005] but there is a large amount of research suggesting that presenting uncertainty information improves decision making, both experimentally [@Joslyn2012; @Savelli2013; @Kay2016; @Fernandes2018] and in practice [@Al-Kassab2014]. As a matter of fact, doing what many authors currently do (providing only a deterministic outcome with no uncertainty) causes decision makers to be *less* decisive and have completely unbounded expectations on an outcome [@Savelli2013]. This reality cannot be avoided by providing secondary or non-specific information such as explaining calculations [@Joslyn2012], explaining the advantages of a recommendation [@Joslyn2012], or expressing uncertainty in vague terms [@Erev_1990; @Olson_1997], all of which are undesirable for decision makers and lead to measurably worse decisions [@Joslyn2012; @Erev_1990; @Olson_1997]. One of the most popular depictions of uncertainty for decision making is a quantile dotplot, shown in @fig-quantdot.

```{r}
#| echo: false
#| warning: false
#| message: false
#| label: fig-quantdot
#| fig-cap: "This plot depicts an example of a a quantile dotplot that expresses the uncertainty associated with a daily maximum temperature. The probability associated with each temperature is expressed with discrete countable bins and the predicted temperature is expressed with a line. Discretised depictions such as this, make decision making in the face of uncertainty easier for the viewer."
set.seed(1)
dotplot_data <- tibble(temp = 10 + round(rnorm(40, mean=10, sd=2))) 
mid <- round(mean(dotplot_data$temp), 2)
dotplot_data %>%
  ggplot(aes(x=temp)) +
  geom_dotplot(binwidth = 0.75, fill="grey") +
  theme_classic() +
  geom_segment(x=round(mid), xend=round(mid), 
               y=-1, yend=0.7, size=2) +
  geom_label(x=round(mid), y=0.7, label=paste0(mid, "°C"),
             fill = "black", fontface = "bold",
             colour="white") +
  scale_x_continuous(breaks = seq(10, 30, 5), 
                     limits = c(10, 30)) +
  theme(axis.line.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank(),
        axis.text.y = element_blank()) +
  labs(x = "Tomorrow's Daily Max Temperature")
```

Not only does communicating uncertainty improve decisions but the mistrust created by communicating certainty in uncertain situations can be exploited. A 6-month survey of anti-mask groups on Facebook during the COVID-19 pandemic showed that the anti-maskers thought carefully about their grammar of graphics and made persuasive visualisations using the same data as pro-mask groups. They did this by exploiting information ignored by the pro-maskers [@Lee2021]. It is understood that deceptive plots can lead viewers to come to incorrect conclusions or significantly overstate effects or risks [@Pandey2015; @Padilla2022] but these incorrect takeaways cannot be mitigated with instructions in how to correctly understand the plot [@Boone2018]. This evidence indicates we are more likely than not to hurt our message when we ignore uncertainty information and trying to raise the general public's plot literacy is an insufficient strategy to curb conspiracy theories and misguided scientific communication.  In direct contrast to this, displaying numerical estimates of uncertainty information has shown to lead to greater trust in predictions [@Joslyn2012; @VanderBles2020]. While @Han2009 found people have more worry when presented with uncertainty regarding health outcomes, this worry is not a bad thing if the concern is warranted given the ambiguous situation.

The disconnect between the research in support of visualising uncertainty and the consensus against it may not be entirely driven by a lack of understanding of the literature. For example, at least one interviewee from the study by @Hullman2020a claimed that expertise implies that the signal being conveyed is significant, but also said they would omit uncertainty if it obfuscated the message they were trying to convey.  Other authors who were capable of calculating and and representing uncertainty well did not do it, and were unable to provide a self-satisfying reason why [@Hullman2020a]. These conflicting motivations are acknowledged in the paper itself where @Hullman2020a says:

> "It is worth noting that many authors seemed confident in stating rationales, as though they perceived them to be truths that do not require examples to demonstrate. It is possible that rationales for omission represent ingrained beliefs more than conclusions authors have drawn from concrete experiences attempting to convey uncertainty". 

An overwhelming consensus among visualisation authors seems to be that uncertainty is secondary to estimations. There is a belief held by those that work with data that the uncertainty associated with an estimate (the noise) only exists to hide the estimate itself (the signal). From this point of view uncertainty is optional information that only exists to hinder our message. Therefore despite its alleged importance, when simplifying a plot uncertainty the first thing to go. This belief is also reflected in the development of new uncertainty visualisations. Often when trying to visualise multi-dimensional data, uncertainty is relegated to unimportant aesthetics in the plot, often of lower importance than the estimate where it is easily ignored [@Correll2018; @Lucchesi2017]. Sometimes uncertainty is not relegated to an undesirable aesthetic but instead incorporated using interactivity to allow users to explore the complicated space themselves [@Potter2009]. Even the literature about uncertainty communication expresses an implicit belief that it is of secondary importance to the estimates or context of the data.

This issues surrounding uncertainty visualisation is not helped by the fact that the term "uncertainty" lacks a commonly accepted definition in the literature. @Lipshitz1997 even commented that “there are almost as many definitions of uncertainty as there are treatments of the subject” . This mishmash of terminology leads to a large body of work, all claiming to finding the best visualisation or expression of of "uncertainty" but most don't even seem to agree on what uncertainty is. The most encompassing definition of uncertainty I have seen comes from @utypo who define uncertainty as **"any deviation from the unachievable ideal of completely deterministic knowledge of the relevant system"**. This definition encapsulates many concepts adjacent to randomness such as predictions, probability mass distributions (PMF), estimate error, and any data that is not a set of deterministic outcomes. This is the definition of uncertainty I will use for the rest of this report.

More commonly uncertainty is defined using a taxonomy rather than a strict definition. There are a few taxonomies for uncertainty, but, just like the definition, most of them are a subset of the one laid out by @utypo. To complete the definition I will include that taxonomy here. @fig-taxonomy is an illustration of the taxonomy presented by @utypo. In this taxonomy, there are three things we need to consider for each "uncertainty" we encounter through the modelling process. First, we need to consider the source of the uncertainty. Is this uncertainty coming from inaccurate measurements or a poorly defined model? This is the *location* of the uncertainty. Second, consider how well you can quantify this uncertainty. Do you know exactly how much measurement error there is in each observation or are you not even aware if there is a measurement error? This is the *level* of your uncertainty, and it ranges from discrete to total ignorance. Finally, consider how this uncertainty came into existence. Is it a result of a naturally random process (epistemic) or is it due to imperfect information and could be improved (aleatory). This is the *nature* of your uncertainty. @utypo then goes on to describe mapping our uncertainty in a 3D space that is defined by its location, level, and nature, but I think the taxonomy is more easily understood as a series of questions we need to consider when we are trying to quantify uncertainty.

![Depicts an illustration of the taxonomy described in @utypo. From right to left the drawing shows the location, level and nature of uncertainty with examples of that category underneath. A specific source of uncertainty from the location can be mapped to a level of ignorance that can increase or decrease (i.e. moving up or down the green line) depending on the nature of the uncertainty. Identifying the location, level and nature of your uncertainty allows you to better understand it. ](taxonomyvis.jpeg){#fig-taxonomy}

While information about the sources of our uncertainty and the type of uncertainty may seem like an unimportant secondary step in uncertainty visualisation, communicating these features of uncertainty helps decision makers make more informed choices. @Padilla2021 found that low forecaster confidence or high model uncertainty both contribute to more conservative judgements by decision makers. Failing to communicate the nature of your uncertainty can result in underestimation or overestimation of failure probabilities [@Kiureghian2009]. Additionally @Gustafson2019 found that the framing of our uncertainty, (i.e. if the source of uncertainty is from a lack of knowledge, approximations, unknown unknowns, or disagreement among parties) was found to not have a detrimental effect on the belief in the estimates, perceived credibility, or behavioural intentions of the decision makers. This means communicating secondary information about your uncertainty can provide additional benefits to decision makers without additional negative repercussions.

The use of uncertainty in high dimensional environments is especially important in energy data. Large models that incorporate spatial-temporal data from many sources and systems are used to predict energy uses in the short and long term. Understanding how to improve and make better decisions in these models is imperative in both the daily operation of the energy sector as well as in the transition from fossil fuels to clean energy. The energy sector needs better heuristics to make energy supply analysis less costly to conduct [@Stenclik2021], therefore it is an incredibly relevant application of uncertainty visualisation techniques. 

## Unvertainty visualisation taxonomies
There are several existing visual taxonomies for visualisation. @Grewal2021 presented a taxonomy that categorized uncertainty visualisations based on discreteness of the distribution and the domain expertise. @Hofmann2012 classified uncertainty distributions by the number of data points required to construct the graphic. @wilke2019fundamentals organised all graphics, into the 7 categories: amounts, distributions, proportions, x-y relationships, geospatial data, and uncertainty. 

Additionally, other taxonomies often identify uncertainty visualisations as a distinct category, however the rules that define what actually *is* an uncertainty visualisation are murky at best. 
Almost every estimate or piece of data is assumed to come from some random process or distribution. Having a visualisation category explicitly for "uncertainty" seems antithetical to the field. Despite this, graphics are categorised according to rules that would seem almost imaginary from a statistical point of view. This results in a *large* number of visualisations that have different names but are functionally identical in what they communicate. A parallel co-ordinate plot, a line plot, a slope graph, and a parallel sets plot are all the same when you break them down into their components. These visualisation are only seen as distinct because of the data focused way we view visualisation. This is not a concrete basis for a visualisation framework considering the ways in which we adjust data using the tidy data framework make it obvious that the distinction between variable and observation is flexible depending on how we want to use the data. 

# Other stuff
It is important to avoid whittling down the problem **too** much. Providing a categorical decision alone is somewhat useless [@Joslyn2012], and visualising a single estimate is akin to providing a decision or expressing no uncertainty at all. 

A study done by @Bella2005 asked participants to adjust two error bars until the means were "just" statistically significantly different, and most people adjusted the error bars until they were just touching. In the case of independent confidence intervals, the p-value of the two-tailed t-test for error bars that just touch is about 0.006 [@Schenker2001]. @Bella2005 also found that few people could incorporate changing information about independence that arises from repeated measure design and most participants were ignorant to the fact that error bars are used for both confidence intervals and standard error bars, two wildly different indicators of precision. 

Thinking about how to visualise specific distributions is not alien to this specific framework. @Wickham2011 discussed how different displays of product plots result in depictions of different marginal, conditional, and joint distributions of data. Their work also did not require any assumptions on the distributions.

The way we currently look at visualisation would classify the error bar plot and the violin plot as visualisations of a "distribution", the scatter plot as a visualisation of a "relationship", and the bar plot as a visualisation of "amounts" (@wilke2019fundamentals). This categorisation hides a lot of important details we draw from a graph. *(Find the paper of the guy who was talking about integrating over a plot)*

The line-up protocol is an application on this idea and considers each visualisation to be a single outcome of some larger distribution [@Buja2009; @Wickham2010; @Chowdhury; @Hofmann2012]. By generating a sample of visualisations from a hypothetical distribution, visualisation authors can check if perceived patterns are real or merely the result of chance.

There are other distributional features, such as discreteness, that are important to consider in uncertainty visualisation. There is a reasonable amount of evidence that cumulative displays or discrete displays (such as a quantile dot-plots or histograms) are the best ways to express mass for decision making and probability estimates [@Fernandes2018; @Hofmann2012; Kay2016; @Hullman2018; @kale2019decision]. 

Elements from a single distribution should be displayed using a single plot, since displaying the features of one distribution across multiple plots makes the information hard to combine and results in some details (such as the estimate error) being completely ignored [@moritz2017trust; Correll2018]. 

Visualisations that correct for this, such as hex maps, do so by colouring and plotting hexagonal tiles that each represent a portion of the dependent parameter (e.g. the population in the case of election results) [@Kobakian]. This means an irrelevant feature, such as land size, is not depicted as important in the map but the location dependency is maintained. Trying to highlight the uncertainty associated with these estimates makes the process even more difficult.

There are four proposed methods of visualising spatial uncertainty that can be made with the `Vizumap` R package [@lucchesi2021vizumap]. 

@fig-bivariate depicts a bivariate map which uses a bivariate colour palette that is created by blending two single hue colour palettes. One colour represents the variable of interest while the other represents the sampling error of that variable. There are two immediate problems with this method. First of all, uncertainty is being expressed with hue and saturation which @Maceachren2012 found to be the worst aesthetics to map to uncertainty to as they don't have an intuitive interpretation. Value has a natural connection to uncertainty (lighter values equate to higher uncertainty and darker values equate to more certainty) so it is a much more appropriate choice. While the `Vizumap` data does depict areas of light and darkness, they are largely irrelevant to the uncertainty measure causing our heuristics to lead us to the incorrect conclusions. The Value-Suppressing Uncertainty Palettes (VSUP) shown in @fig-vsup maps estimates to the hue and error to the value thereby creating a more intuitive plot [@Correll2018]. Additionally, at high levels of uncertainty VSUP only has one output colour, which prevents viewers from decrypting any particular value and also avoids enforcing a binary encoding of significance [@Correll2018]. Unfortunately VSUP are not easy to combine with packages like `Vizumap` which leaves it still somewhat difficult to express this encoding in practice, however the combination of a bivariate map with VSUP has shown to improve decisions in the face of uncertainty [@Correll2018]. 

@fig-pixel depicts a pixel map. Pixel maps are similar to HOPs since they present a sample of possible values for the estimate, rather than a single value and an associated uncertainty. Currently the effectiveness of a pixel map is yet to be shown in any experiments, and it may turn out to be a poor encoding of uncertainty information, however it is a promising visualisation. Unfortunately, mapping a distribution of colours to numerical values is currently required to extract any numerical estimates from the plot which is a relatively difficult mental task. Therefore the pixel map might be more effective if values were written explicitly on top of the pixels. The pixel map is also quite computationally expensive and hard to interpret when the relevant geographical areas are small relative to a large map, so it is best used on simpler smaller geographical areas.

@fig-exceed is a exceedance probability map that shows the probability of the estimate being over a certain value. This plot was developed specifically for decision making so it is a simple visualisation of a single parameter [@Kuhnert2018]. An exceedance probability map map is actually very similar to a choropleth map, but instead of expressing an estimate, it shows a probability. Therefore this plot is only able to express probability through a change in information rather than an improvement in visualisation techniques.

@fig-glyph is a glyph map that uses colour of a glyph to express an estimate and the rotation of the glyph to express uncertainty. Orientation has no intuitive link to uncertainty and should be avoided at all costs [@Maceachren2012]. Additionally, by mapping the estimate and its error to distinctly different features, this plot makes it easier to ignore the uncertainty associated with an estimate.

```{r}
#| eval: false
#| echo: false
data(us_data)
data(us_geo)
# Data stuff
us_data <- us_data %>% mutate(Estimate = pov_rate,
                              Error = pov_moe)
poverty <- read.uv(data = us_data, estimate = "Estimate", error = "Error")

# Bivariate plot
# make pal 
customBivPal3 <- build_palette(name = "usr", colrange = list(colour = c("chartreuse4", "darkblue"), difC = c(3, 4)))
customBivPal1 <- build_palette(name = "usr", colrange = list(colour = c("tan2", "lightskyblue"), difC = c(1, 1)))
# Make map
usBivMap <- build_bmap(data = poverty, geoData = us_geo, id = "GEO_ID", terciles = TRUE, , palette = customBivPal3)
# make key
usBivKey <- build_bkey(data = poverty, palette = customBivPal3, terciles = TRUE)
# attach key (+ visualise)
attach_key(usBivMap, usBivKey) 
ggsave("ideas/confirmation/bivariatemap.jpeg", width = 10, height = 5)

# Pixel Map
us_data$GEO.id2 <- as.numeric(us_data$GEO.id2)
ca_data <- subset(us_data, us_data$GEO.id2 > 6000 & us_data$GEO.id2 < 7000)
ca_data <- read.uv(data = ca_data, estimate = "Estimate", error = "Error")
row.names(ca_data) <- seq(1, nrow(ca_data), 1)
ca_geo <- subset(us_geo, us_geo@data$STATE == "06")
pix <- pixelate(ca_geo, id = "region")
df <- data.frame(region = sapply(slot(ca_geo, "polygons"), function(x) slot(x, "ID")), name = unique(ca_geo@data$GEO_ID))
ca_data$region <- df[match(ca_data$GEO_ID, df$name), 1]
ca_data$region <- as.character(ca_data$region)
unifPixMap <- build_pmap(data = ca_data, distribution = "uniform", pixelGeo = pix, id = "region", border = ca_geo)
view(unifPixMap)
ggsave("ideas/confirmation/pixelmap.jpeg", width = 7, height = 7)

# Glyph Map
co_geo <- subset(us_geo, us_geo@data$STATE == "08")
us_data$GEO.id2 <- as.numeric(us_data$GEO.id2)
co_data <- subset(us_data, us_data$GEO.id2 > 8000 & us_data$GEO.id2 < 9000)
co_data <- read.uv(data = co_data, estimate = "Estimate", error = "Error")
usGlyphMap <- build_gmap(data = co_data, geoData = co_geo, id = "GEO_ID", size = 80, glyph = "icone", border = "county")
usGlyphKey <- build_gkey(data = co_data, glyph = "icone")
attach_key(usGlyphMap, usGlyphKey)
ggsave("ideas/confirmation/glyphmap.jpeg", width = 7, height = 5)

# Exceedance probability map
poverty <- read.uv(data = us_data, estimate = "pov_rate", error = "pov_moe")
quantile(us_data$pov_rate)
pd <- quote({ pexp(q, rate, lower.tail = FALSE) })
args <- quote({ list(rate = 1/estimate) })
pdflist <- list(dist = pd, args = args, th = 30)
usExcMap <- build_emap(data = poverty, pdflist = pdflist, geoData = us_geo, id = "GEO_ID", key_label = "Pr[Estimate > 30]")
view(usExcMap)
ggsave("ideas/confirmation/exceedmap.jpeg", width = 10, height = 5)
```


::: {#fig-maps layout="[[59,-2, 39], [59,-2, 39]]" layout-valign="bottom"}

![Bivariate Map](bivariatemap.jpeg){#fig-bivariate}

![Pixel map](pixelmap.jpeg){#fig-pixel}

![Exceedance probability map](exceedmap.jpeg){#fig-exceed}

![Glyph Map](glyphmap.jpeg){#fig-glyph}

Four spatial uncertainty visualisations that can be made using the `Vizumap` package. Each plots depicts a map with a combination of estimate and error expressed using (a) a bivariate colour palette, (b) a sample of outcomes, (c) a statistic that uses both the error and estimate in its calculation, and (d) using colour value for the estimate and rotation for the uncertainty. The pixel chart (b) gives a good sense of uncertainty, the exceedance probability map (c) is easy to read, and the bivariate map (a) and glyph map (d) are hard to interpret because the estimate and the uncertainty are not well integrated with each other.
:::


![An example of the Value-Suppressing Uncertainty Palette designed by @Correll2018. The change in hue shows a change in the estimated value, while the change in value highlights a change in uncertainty. The estimates merge together as the uncertainty increases to prevent viewers identifying insignificant differences between values.](vsup.png){#fig-vsup width=35%}



The four plots depicted in @fig-maps are merely some suggested solutions for a particular case of uncertainty visualisation. They are great when we want to highlight the error associated with a particular estimate, or visualise a sample, but if we need an idea of a more complicated feature of the distribution (such as mass) they are not so useful. What is interesting about this spatial uncertainty example is the implicit hierarchy we put on the error and the estimate. @fig-bivariate set the estimate and error at the same level of importance; @fig-glyph established the estimate to be of higher importance than the error; and @fig-pixel and @fig-exceed both visualised a feature that combined the error and estimate (by expressing a sample and a parameter that combined the error and estimate respectively) placing both at the same level of importance. What may have been less obvious is that all four plots place spatial information at the highest level of importance. If the only thing you want from your plot is a sense of estimates with respect to their position in space, these plots work well, but sometimes other pieces of information are more important. By always assuming features such as the spatial context are always the most important aspect of a plot, we kneecap research and don't consider the wide array of ways we can express complicated concepts such as exchangeability and location.

A hierarchy of elementary perception tasks is not a new idea in visualisation. @Cleveland1984 found a natural ordering of 10 elementary perception tasks in term of how accurately participants could extract information that was mapped to that feature. The hierarchy established was:

1) Position along a common scale

2) Positions along non-aligned scales

3) Length, direction (slope), angle (starting from the same origin)

4) Area

5) Volume, curvature

6) Shading, colour saturation

While @Cleveland1984 notes that these tasks are not exhaustive nor mutually exclusive, and accuracy is not the only metric that should decide if a graphic is worthwhile, this hierarchy does provide a useful rule of thumb in understanding the importance of information in a graph. This paper is also quite old, so more modern aesthetics such as time (for an animation) or obscure aesthetics such as rotation (which was used in the glyph map) are not tested. 

It is also important to keep in mind that just because information is in a graphic, that does not mean it will be "seen". The phenomena of inattentional blindness shows that there is no perception without attention and it is powerful enough that participants can fail to be aware of random objects appearing on a screen or a gorilla walking through a basketball game [@simons1999gorillas; @mack2003inattentional]. Therefore if information is mapped to graphical elements that are so low on hierarchy they can be ignored, they might as well not be there at all. The people who don't plot uncertainty because they think its unimportant and the people who relegate uncertainty to the lowest ranking aesthetic on the list are both saying the same thing, "I think the uncertainty is unimportant". Including uncertainty is worth very little if no attention is left to see it. This does not mean we cannot put a *large* amount of information in a graphic. Glyph maps can be used to depict the multi-dimensional information in spatial-temporal data by mapping line plots to map locations, but we still need to decide what information is important. The map can either present trends in the global or local variance depending on whether or not the line plot is scaled globally or locally [@Wickham2012], however smaller details are almost impossible to convey. No matter how much information we try and put in a plot, there will always be only a handful of key takeaways.

Not only should we considered the hierarchy in the information we display, but we also need to consider the heuristics that connect some pieces of information to specific elementary tasks. For example @Hofmann2012 showed that polar co-ordinates are more effective than cartesian co-ordinates when considering data that depicts a 360 degree direction (a case where polar co-ordinates has a natural interpretation). Uncertainty also has a natural mapping that should be considered when we express it in a plot. Error is best mapped to fuzziness, location, and colour value; arrangement, size and transparency are an OK second choice; but saturation, hue, orientation and shape are unacceptable and have no intuitive connection to variance [@Maceachren2012]. No only do the graphical elements we map our features to matter, but the direction matters too. Graphical elements that are more fuzzy (fuzziness), further from centre (location), lighter (colour value), poorly arranged (arrangement), smaller (size), more transparent (transparency) are perceived to be more uncertain [@Maceachren2012]. This idea also extends to interval estimation, where questions about probability are best answered with gradients and questions about start and end times are easiest to answer with ambiguation [@Gschwandtnei2016]. Heuristics can work against us just as much as they can work for us. The sine illusion can cause the confidence interval of a smoothed sine curve to seem wider at the peaks than the troughs, causing us to underestimate uncertainty associated with changing values [@Vanderplas2015]. Therefore we should not only keep the hierarchy of information in mind when we map features of our distribution, but also take advantage of these intuitive mappings when we can.

The final consideration when deciding what information to depict is whether or not additional information will clutter the graph. Our visualisation should aim to show enough information to solve a task while avoiding irrelevant distracting information [@kosslyn2006graph]. While including additional features can increase the accuracy of some conclusions, it can also bias or discount others. Including mean estimates on depictions of mass can cause people to discount the uncertainty information and use the difference between means as a proxy for the probability distribution [@Kale2021]. 

In the introduction, when I displayed the power of visualisation using Anscombe, I implied that visualisations have a miraculous power to tell us what is important about our data. That is not entirely true. While Anscombe's quartet shows the importance of using visualisation to find hidden details, it also highlights the importance of a visualisation author who knows how to express what is important. If I provided a visualisation of Anscombe's quartet but used a different combinations of variables, presented an expression of mass, or provided a series of error bar plots (which would have all been identical), the interesting features of the data would have remained hidden. We are often not so lucky to already *know* the best way to visualise our data, so having rules that allow us to understand *what* we are visualising is the first step in finding that "best perspective".  

# Bibliography

```{r, include=FALSE, eval=FALSE}
library(spelling)
qmd <- "ideas/confirmation/confirmationreport.qmd"
ignore <- readLines("WORDLIST")
check_spelling <- spell_check_files(
  qmd,
  ignore = ignore,
  lang = "en_GB"
)
if (nrow(check_spelling) > 0) {
  print(check_spelling)
  stop("Check spelling in Qmd files!")
}
```