{
  "hash": "e9def48b158744a37c2e427d5db3939e",
  "result": {
    "markdown": "---\ntitle: \"What do we mean when we talk about uncertainty?\"\nauthor: \"Harriet Mason\"\ndate: \"2023-03-18T00:00:00Z\"\nlastMod: \"2023-03-18T00:00:00Z\"\nimage: feature.jpeg\nbibliography: references.bib\ncategories:\n  - data visualisation\n  - statistics\ntags:\n  - data visualisation\n  - statistics\neditor: \n  markdown: \n    wrap: 72\nknitr:\n  opts_chunk: \n    warning: FALSE\n    message: FALSE\n    echo: FALSE\n---\n\n\n## High Variance Lifestyles\nRecently I asked my doctor if I could be put on some kind of mood stabilisers. I had been experiencing a lot of aggrevation, stress and general negative vibes as a result of trying to tie up the tenancy of my due to having to engage with my ex-housemate. Over the few weeks prior to my doctor appointment, my housemate sara had hit my dog, hit me in the face with a plate (which resulted in the police being called to the house), stole some of our stuff, refused to sign the lease transfer documents, left a large amount of broken furniture at the house, refused to pay her outstanding $700 in rent and bills, set fire to the mantle and refused to fix it, constantly posted on social media calling myself and my other housemates crazy children, tried to convince the person who we found to take over her lease to not move in, and finally ghosted us when we tried to confront her about these things. At one point the house group chat turned to asking if it would be easier to just kill her and deal with the police than continue to deal with her. Upon hearing this my doctor said he didn't think I needed mood stabilizers because someone terrorizing your place of living and stealing your things and assulting you would lead any reasoable person to be upset and he didn't think mood stabilisers would help. While I somewhat agree, seeing her message the new housemate saying she \"wants this to be over and done with already\" should not be enough to send me into a two day rage. This conflict which would seem completely out of the ordinary to most people is a regular occurence for me and while I understand it is extreme, at some point I have to be able to work at a job. If my plan for emotional regulation is to assume my mood will usually be in the healthy range and handle the few cases it isn't when they arise, then I might as well accept my current situation which is 100 productive days in the year. There are obvious triggers and ways to manage this. I will never be able to entirely remove \"off days\" from my life, but I can decrease their frequency and length with a better understanding of its sources. If I understand *what* about my demon housemate Sara and others like her sends me into an angry death spiral, I can redirect the energy and have a better control of the situation. Specifically, understanding the sources of the variance in my life will help me understand the best ways to manage it. Uncertainty in a model is quite similar. In a lot of ways, I think of my struggles to contain my mood as similar to my struggles to estimate uncertainty.\n\n## Sources of Uncertainty\nLets start this section off with a simple plot hopefully everyone has seen before. This is a plot taken from Forecasting: Principles and Practice [@robsbook]. It is a simple depiction time series data, but I have also included a forecast (using an ARIMA model) that has some uncertainty surrounding it.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\nIf you use the fable package to make your forecasts, the default plot will display a confidence interval around your forecast. I enjoy this feature which probably won't shock anyone. Sometimes, when I try to think about estimating a true confidence interval, accounting for every possible random event, I become so overwhelmed it gives me anxiety. This is not an uncommon feeling it turns out. In my previous post I discussed reasons people didn't visualise uncertainty, one of which was people being \"uncertainty about the uncertainty\". This uncertainty leads people to prefer to do nothing (visualise no uncertainty) than even start to deal with the insurmountable problem of quantifying uncertainty. Default confidence intervals do not require users to understand and quantify the uncertainty themselves, but it does force *something* to be put down in terms of quantifiable uncertainty. It prevents the \"omission through incaction\" stance because in order to *remove* the uncertainty, you need to take action. Obviously I would prefer people understand the uncertainty behind their models, but beggars can't be choosers.\n\nNow that we have some depiction of some uncertainty this leads to move questions (which it turns out people hate, which is another reason they dont visualise uncertainty). What \"uncertainty\" is this plot actually depicting? Like *where* did the numbers that make those confidence intervals come from? *How* did we even decide what is worth calculating? *What* situations and outcomes do these confidence intervals describe? To these questions I say, lets hold on and take a step back. I could hear your voice breaking into a fever pitch (or I guess your voice as it sounds in my head). The mean green uncertainty machine isn't breaking into your house and rifling through your stuff and stealing your belongings. \n\n<center>![](meangreenmachine.jpeg)</center>\n\nUnlike you, I actually have something to fear. Your uncertainty problem is actually (somewhat) easy to manage, you just need to understand it. That didn't work with calming with my ex-housemate, I tried.\n\n# Organising Uncertainty\nThere are a few of typologies for uncertainty, but I think all of them end up being subsets of the one laid out in the paper \"Defining Uncertainty\" [@utypo]. Since that typology includes the others, we are just going to work with that work (its also an easy to read paper that gets a lot across with its word count). The paper also uses a definition of uncertainty that I enjoyed. They defined uncertainty as any departure from the unachievable ideal of complete determinism. Therefore if we can't predict something with perfect accuracy, it had uncertainty. \n\nIn this typology, there are three things we need to consider for each \"uncertainty\" we encounter through the modelling process. First, consider the source of the uncertainty. Is this uncertainty coming from inaccurate measurements or a poorly defined model? This is the *location* of the uncertainty. Second, consider how well you can quantify this uncertainty. Do you know exactly how much measurement error there is in each observation or are you not even aware if there is or isnt measurement error? This is te *level* of your uncertainty, and it ranges from discrete to total ignorance. Finally, consider how this uncertainty came into existence. Is it a result of a naturally random process (epistemic) or is it due to imperfect information and could be improved (aleatory). This is the *nature* of your uncertainty. With this, we can map every uncertainty (theoretically but I'm not sure of the use practically) in a 3D space that is defined by its location, level, and nature.\n\n<center>![](3duncertainty.jpeg)</center>\n\nYou may be thinking to yourself, well this typology is well and good, but how on earth do I use it? Lets go through an example using the data we used to forecast earlier.\n\n# Applying the Typology\nFirst, lets take a look at the data we were forecasting with before, and where those confidence intervals came from.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nYou may not be super experienced with time series data or forecasting, and that's OK (honestly I have taken like two courses in it and then pretended forecasting doesn't exist outside that). \n\n\nYou need to bring this insible under the murky water uncertainty and bring it into the light, giving us a bright and shining visible uncertainty.\n- whenever you encounter a new uncertainty you have one of two options.\n1) try and quantify it and include it in your intervals (usually by expanding it)\n2) give up on trying to quantify it and include it as an assumption.\n\n\n# Random notes\nLets make this easier. If I use the fable package to  have some time series data, and I make some forecast, \n* Incorrect model or distribution\n* Measurement errors\n* Sampling error\n* Events outside the sample\n* Black Swan Events (pandemic)\n- interesting that we give confidence intervals as 95%. Every way we talk about uncertainty is directly related to hypothesis testing which is a very non-intuitive way of thinking about uncertainty. What if we did epistemic and aleatory confidence intervals. This may be a stupid idea when I read it later, not at midnight.\n- From the Role of Uncertainty \"We can see that trust it is highest when the user is either aware of no uncertainties or mistakenly believes there are no uncertainties\". This makes me suspect that people are trusted more when they don't display uncertainty BECAUSE the audience has assumed there is none.  If you don't display uncertainy, I think it is assumed there is none. maybe we could test this by making people aware of uncertainty and not and seeing if their reaction to to the plot when there is no uncertainty displayed mimics their beliefs when they know for certainty there is no uncertainty. Like get them to do a decision making task or something. It makes me think about the cognative test I had to do where uncertainty existed but was not made explicitly clear to me.\n- Could be fun to test what testing method provides a better understanding of audience insight? Is that too meta?\n- \"Open questions generally support visualisation overviews rather than details views\" I wonder if the way we ask questions about visualisations changes the way people see them.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}