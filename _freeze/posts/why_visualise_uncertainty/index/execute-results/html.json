{
  "hash": "4d80040c1afbe90f15c0ae9c5e84a4ce",
  "result": {
    "markdown": "---\ntitle: \"Do You Have a Good Reason to Avoid Visualising Uncertainty, or are You Just Being Lazy?\"\nauthor: \"Harriet Mason\"\ndate: \"2023-02-25\"\nbibliography: references.bib\ncategories:\n  - data visualisation\n  - statistics\ntags:\n  - data visualisation\n  - statistics\n---\n\n\n## The Wombat Conference\nRecently I went to a conference with the central topic of visualising data. The conference was great and it was the first time i have ever been able to understand most of most of the speaches. Usually I just stare at the speaker's slides and wonder if I am the only one who has no idea what they are talking about. There was one overwhelming sentiment shared by all the speakers that seemed a little disastrous to my research. Speaker after speaker went to the podium, started their speach, and said they didn't visualize uncertainty (except keynote speaker but I was late and missed it). As a PhD student whose research centers on visualising uncertatiny, this could be seen as a bit of a spanner thrown into my work. I will admit that it became a running joke in my notes, to see how long until the speaker either admitted they don't visualise uncertainty, or just outright dismissed it as feasible in their work. I started to wonder if living in the woods and carving sticks would be a more fruitful career than what I was currently doing. I have since spoken about this to multiple friends who have admonished those who openly reject visualising uncertainty, but I actually repsect the honesty. In trying to improve uncertainty visualisations, I have noticed that uncertainty is rarely visualised and there must be a reason for it that goes beyond \"the current methods aren't good\". We can all sit here and say \"we should visualise uncertainty\" but the reality is, nobody actually does and everyone has some reasoning for it that outweighs misrepresenting our results. Even if I spend months working on a new way to visualise uncertainty, without understand why nobody does it, my work would be born to live in a frame on my mothers wall, read only by myself and examiners, and used by nobody.\n\n## When to NOT Visualise Uncertainty\nWhen I was in high school, my fancy private school paid a lot of money to have a speaker come in and talk to my cohort about communicating statistics. To get his point across the speaker gave an example on smoking. His speech went something like this:\n\n\"People are really bad at applying probabilities to themselves, especially when the probability relates to something bad. That means that if the government wants people to stop smoking to decrease the burden on the health care system, they can't communicate it through probability. I'm sure that everyone in this room thinks that if you smoke it is certain that you will eventually get cancer and die, that is quite frankly not the case. The reality is, even if you smoke you actually only have about a 1% chance of getting lung cancer. Obviously it also leads to other diseases and a lower quality of life, but it is a far cry away from  it being certain you will get cancer and die. The reason it is communicated with uncertainty is that we don't want anyone to smoke, and we achieve that by communicaing with certainty even if it is a misrepresentation of reality.\"\n\nAt this point our head of pastoral care interrupted the speaker and says, completely seriously, \n\"Sorry everyone this man has no idea what he is talking about, or he is lying. If you smoke it is certain you will get cancer and you will die. There is no probabiliy about it. OK buddy,\" he continues, guesting to the speaker \"keep going\". \nThe speaker just stood there shocked for a couple seconds, laughed and then, as instructed, kept going. I imagine he remembered they had already paid him so if they wanted to publicly discredit him and undermine his entire point, it was no skin off his back. I silently wondered if our school fees would be cheaper if they just hired whatever nightmare speaker they actually wanted. I'm sure some guy who tells students they will go to hell if they engage in premarital sex or do drugs would be much cheaper than an expert in communicating statistics, but I digress. This may seem irrelevant, but this is a story about how even in a strict context, people don't trust their audience to correctly understand probabilities no matter how they are communicated.\n\nMost people think the reason nobody visualises uncertainty is a lack of trust in peoples ability to understand probability. I do somewhat understand how people feel when they express this sentiment. I mark third year statistics assignments and only half of the students seem to know what a random variable is. That being said, there is a difference between However, the conference made it clear that there are many that people avoid visualising uncertainty that are not just to do with assuming the worst about the intelligence of your audience. Having now read quite a few papers on the topic, finding out why people don't express the uncertainty in their work is an exercise into insanity. \n\n<center>\n![](patrickmeme.jpeg)\n</center>\n\nPrior to reading into it I suspected that the reason authors did not visualise uncertainty was because there were just not enough good and intuitive methods. I would be unsurprised if this was a widely held belief. Now that I have read some research one it, I actually think its just that people are incentivised not to. The problem is not the available methods or the audience, its human psychology. This is not to say that if someone says current methods are lacking they are always making up an excuse (for example, visualsing uncertainty on maps is very difficult) but it just highly likely that they are. Below I will go though the most common reasons cited for failling to express uncertainty, and why they are lacking once you engage in the literature. Then you might see what I mean.\n\n## The Excuses (and The Rebuttals)\n  \nThere is a large amount of literature providing new ways to visualise uncertainty and showing its effectiveness, but much less on why people don't do it. I am going to focus on the reasons provided in \"Why Authors Don't Visualize Uncertainty\" by Jessica Hullman because this is one of the few detailled reviews I could find that actually did a structured interview with visualisation authors to find out if they visualised uncertainty and why they would chose not to [@Hullman2020a]. \n\nBefore going into each reason and rebuttal, I want to make it clear that majority of those interviewed or surveyed for Hullman's paper agreed that expressing uncertainty is important and should be done more often [@Hullman2020a]. As a matter of fact, some people agreed that failing to visualize uncertainty is tantamount to fraud [@Hullman2020a]. Despite this, only a quater of respondents included uncertainty in 50% or more of their visualisations [@Hullman2020a].  This means people are convinced that visualising uncertainty is important from a moral standpoint, but they have still been able to provide self sufficient reasoning that allows them to avoid doing it. That doesn't mean the reasoning provided follows consistent and sound logic. For example, at least one interviewee from Hullmans survery claimed that expertise implies that the signal being conveyed is significant, but also said they would omit uncertainty if it obfuscated the message they were trying to convey [@Hullman2020a]. Even some authors who were capable of calculating and and representing uncertainty well did not do it, and were unable to provide a self-satifying reason why. The clear friction in the explanations below are obvious but for the time being I will ignore it and take each claim at face value. At the end I will discuss the clear issue of backward justification.\n\n--------------------\n\n#### Reason: Expertise  \nSome intervieees claimed that the uncertainty would add little to the plot because they only present statistically significant findings and the audience trusts their expertise.\n\nOne participant in Hullman's study said \"Most people will trust the doctor, not necessarily because the information itself was trustworthy, but because the doctor was.\" when referencing why a certain level of expertise allows one to omit uncertainty [@Hullman2020a].\n\n#### Rebuttal  \nI personally wish my doctor would give me probabilities and I have spent hours complaining to friends about the ones that don't. To make descisious about risk that *others* are taking on because *you* are an expert is wildly infantilising. I broke my finger when my usual GP was on leave and had to see someone else who said it was \"probably nothing to worry about\" and sent me home without an x-ray.  I wish he had communicated the amount of uncertainty about that because I had to get a $5000 hand surgery 3 months later to correct his mistake.  Because the uncertainty about his decision and the costs associated with an incorrect descision was not communicated to me, I took on a much higher risk than I was comfortable with. Significance is arbitrary, and communicating uncertainty around that value is necessary for the people making the descisions.\n\n--------------------\n\n#### Reason: Clutter  \nWhen showing a graphic for a short period of time (such as on TV) you can only present one idea per graphic, and uncertainty will clutter the visualisation.  \n\n#### Rebuttal  \nI find this reason interesting, because it implies a hierarchy where the estimate is above the uncertainty. It leads me to wonder, if you can only show one idea, why not show the uncertainty? Something as simple as presenting a range instead of a point estimate would give an idea of central location as well as degree of uncertainty in a lot of cases. \n\nI think the clutter argument speaks to an unspoken belief of those that work with data, that the uncertainty associated with an estimate (the noise) only exists to hide the estimate itself (the signal). From this view, uncertainty is only seen as additional or hindering information, therefore despite its alleged importance, when simplifying a plot uncertainty the first thing to go.  \n\nPeople being unable to make quick decision's using uncertainty may not even be true. **Maybe bus example but there might be a better one?**\nUncertainty can also be used to convey adjacent information. In forecasting the uncertinty visualisation adds to the plot, i.e. it lets you know what is data and what is a forecast from a model, I suspect it is frequently done in this area for this reason.\n\n#### Reason: Audience Understanding\nThe general public does not understand randomness so including uncertainty will only confuse the audience.\n\n#### Rebuttal\nThis statement has two halves that are technically true if you constrain it. For example, the statements \"the general public does not understand *the difference between freuqentist and baysian statistics*\" and \"*some* people struggle with uncertainty\" are both true. What is not true is the statement above. It seems to arrive at this statement, half of two correct statements were combined to make one incorrect statement.\n\nFirst, lets address if the general population can understand uncertainty. I think blanket yes/no conclusions about whether or not uncertainty was understood ignore the intricacies of understanding uncertainty that comes through in the research. The general gist seems to be this. Can laypeople interpret uncertainty in a way that is consistent with frequentist philosiphy? No [Hoekstra2014]. Can laypeople reliably translate an error bar plot to an equivalent hypothesis test? No [@Bella2005]. Can laypeople read an uncertainty plot and make accurate and efficient decisions factoring the uncertainty into their choices? Yes [@Kay2016] [@Fernandes2018].\n\nWhile *some* people struggling with uncertainty, the *population* as a whole does not.  My previous housemate told us the fire hazards she created were not a problem because \"The house has never cught However, the population as a whole does not. There are at least two studies showing laypeople cant make time constrained, acuate, choices with an uncertainty diagram small enough to fit on their phone screen when factoring in bus arrival times [@Kay2016] [@Fernandes2018]. Additionally, people got better at understanding the uncertainty plots the more they used them [@Kay2016]. Some participants had a lower baseline that the general public (the people that do not undertand uncertainty) but most showed an improvement in decision making as the study went on. This indicates that laypeople have the ability to learn and improve their ability to incorporate uncertainty information. Refusing to express uncertainty because people dont understand them, prevents people from improving in their ability to understand the plots, causing those that may not be able to understand uncertainty to continue to be bad at it.\n\n#### Reason: Trust with the Audience (current)\nCommunicating uncertainty will result in people trusting our results less rather than more. \n\n#### Rebuttal\nThis just isn't true. There are a few studies indicating that people trust visualisations that express uncertainty more than those that don't. Multiple participants from Hullman's study seemed to equate \"trust\" with \"not being questioned\" which I would argue are not equivalent. Many believed that you could only visualise uncertainty after you had trust with the audience, stating that if you visualise your uncertainty prior to that \"someone will inevitably ask, 'how did you get these numbers?'\".\n\n\n#### Reason: Complicates Descision Making\nUncertainty confuses people and makes it harder for them to make decisions. Because of cognative overload we want to be careful about conveying important information (floods & sick dog examples). \n\n#### Rebuttal\nRemoving uncertainty makes the descision making process easier in the same way presenting no choices does. Artificially. (alternative presenting a threshold decision (yes/maybe/no for evacuations)\n\n\n#### Reason: Multiple Sources of Uncertainty\nSometimes there are multiple layers of uncertainty which are too hard to communicate so it is ignored.\n\n#### Rebuttal\n\n#### Reason: Fraud\nNot visualising uncertainty on purpose to misrepresent findings. This one is more difficult to police because even making a selection (before visualisations are even made) introduces bias.\n\n#### Rebuttal\nThis is something people would never admit to if everyone cared about scientific integrity, but unfortunately this is well documented too. Hullman's paper quotes an interviewee justifying not showing unvertainty in their visualisations because it hid the signal since the \"data wasn't reliable and uncertainty seemed too big\". Here I think about the scene from the Big Short, where Steve Carell's character asks his colleague why the real estate agents who are openly committing fraud are confessing, to which his colleagues tell them that they are actually bragging.\n\n#### Reason: Prescision\nFear that uncertainty will imply unwarranted prescision in estimates\n\n#### Reason: Common Knowledge\nA tendancy to think that the presence of uncertainty is common knowldge\n\n#### Reason: People Dont like it\nPeople cannot tollerate uncertainty and it creates negative feelings.\n\n## Why do I think people dont visualise uncertainty?\nThey don't want to. This does not mean everyone who doesn't visualise uncertainty is evil. Widespread issues like this are almost universally created by systematic problems and norms. But the rationale provided by the participants in these studies **reek** of back justification. Hullman herself notices this, claiming in her paper \"It is worth noting that many authors seemed confident in stating rationales, as though they perceived them to be truths that do not require examples to demonstrate. It is possible that rationales for omission represent ingrained beliefs more than conclusions authors have drawn from concrete experiences attempting to convey uncertainty\" [@Hullman2020a]. I took this as a fancy academic way of saying \"I think these people are full of it and are making up random reasons to justify why their actions don't reflect their beliefs\". \n\nThis is not to say I have a poor view of the participants in the study. I think they are normal people doing what people do. Rather, I think that discussing the results with an absence of acknowledgement of the human psycology that got us there is disengenous in of itself. Back justifying is frighteningly common and almost a natural way for the brain to operate.\n\nSome have suggested the refusal to visualise uncertainty results from a norm that people refuse to admit. I have to agree with this sentiment. From personal experience visualisation as a whole seems to be generally looked down upon in science. There is a large focus on \"what is there\" and evidence and less on \"is the communicated in a way that is easy to understand\". As a matter of fact, I think there is often an effort to purporsely make research harder to understand. I need to read papers for my PhD and often I am floored by how difficult some papers are to understand, even though I am at a level where a paper within my field should not leave me confused. I also think of lecturers during my undergrad gloating to students about high fail rates and difficulty of the course. Obviously there is a prestige to doing something so complicated others struggle to understand it. When you hear that the proof for the Poincare conjecture (the only millenium prize problem to be solved) could only be understood by experts meeting at a conference and understanding the work in groups over several days, it inspires an idea of godlike intelligence. Therefore, if something is hard to understand it is a more advanced idea, and you are smarter for knowing it. Of course, something can be hard to understand because it is poorly communicated, not only because it is difficult, but that seems to be lost on a few researchers. A man asking for directions to the train station in gibberish is also difficult to understand, but he is unlikely to stand in front of a multivariate calculus lecture and brag about still being lost. \n\nI want to clarify that I don't think people are avoiding visualsing uncertainty because its more prestigious to avoid doing it. However, I do think visualising uncertainty, and visualisation as a whole have become caught up in the scientific quest for prestige through gatekeeping the field with poor communication. \n\n\n# Solutions\nI think there are several conflicting sentiments and norms creating this issue.\n\n## Unplaced comments\n- estimates do not require as much thinking as uncertainty. You may assume a normal distribution and identical appearance between your sample and forecst implicitly when you do an estimate, but you make these things explicit when you present uncertainty. I wonder if people are unaware that they are making these assumptions when they produce estimates.\n- People draw an uncertainty bound around data that does not have any uncertainty expression if they are aware that it is only an estimate. In the absence of any uncertainty estimates it would be interesting to see where people naturally draw their uncertainty bounds (if they are at a level of significance) and what impacts them.\n- This reminds me of unbiassed vs consistent estimators. Even the estimators themselves have been selected on the principal that a low variance is better than a high variance reguardless of the point prediction.\n- Think of how to test assertions vs rebuttals\n-- Ask people (maybe done) when someone uses uncertainty what do you think of (what does it mean)\n-- Is there uncertainty in this plot (what is it) if none what would be an addition to the plot to convey it\n- I wonder if I visualise uncertainty in forecasting models more because 1) the model gives a clear divide of no uncertainty (in the data) and the uncertainty (in the model). Also it is the default.\n-- software developers should include uncertainty as a default\n- Danger of using visualisation to determine signal strength (without uncertainty) in that LDA paper\n- The secondary nature of the uncertainty aspect of models and estimates is evidenced by the fact that they are not as immediately and widely available as measures of central tendancy.\n- I think the issue of \"fraud\" and \"people don't understand uncertainty\" are actually connected. There are many incentives to represent work as more certain than it is. For every single instance where a point prediction is appropriate, a range could also suffice. They are similar in the amount of information to process, but people opt for a point rather than a range. In some instances it might be confusing to give a range (like temperature) but \n- incentivise visualising uncertainty. Make the best and easiest to understand visualisation the one that includes uncertainty. The forecast plot makes it clear where the data ends and the forecast starts, adding additional information that is adjacent to the uncertainty and gives a second incentive for visualising the uncertainty.\n- Saying \"it will happen\" vs \"it has a 10% chance of happening\" is not only for not trusting the audience, it is more about speaking to individual vs group. If you speak to a large enough number of people, the uncertainy disappears. It is not \"you have a 10% chance of getting cancer\" and becomes \"10 of you will get cancer\". \n- I wonder if the visualisations have the same issue as electoral systems. If an electoral system is too simple, highly educated people don't vote because they don't respect the process, if it is too complicated, poorly educated people don't vote because they don't understand it. Making an electoral system is a constant ballancing act between these two forces and I think making a good visualisation is the same.\n- Better communication aroud the estimates themsevles. \"nobody experiences the average\"\n- James Goldie: uncertainty is confusing to audiences so it is skipped. instead we select cases where the pattern is clear and discuss uncertainty only if it is relevant.\n- Casey Briggs: we provide trend forecasts instead of predictions because we dont convey uncertainty\n- Liam Mannix: Predictions that don't come true make the public lose confidence.\n- Michael Lyndmore: From my experience, policy makers hate uncertainty, so it is taken out.\n\n\n# References",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}