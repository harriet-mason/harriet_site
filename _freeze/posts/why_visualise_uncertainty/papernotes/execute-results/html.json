{
  "hash": "e6c53740a5d832925b34dcfd852e3f43",
  "result": {
    "markdown": "***\ntitle: \"Paper Notes\"\nauthor: \"Harriet Mason\"\ndate: \"2023-02-25\"\noutput: html_document\n***\n\n\n\n\n\n# Why People Don't Visualise\n## Reasons For\n### Why Authors Dont Visualise Uncertainty\n\nReference: @Hullman2020a\n\n#### This study\n* survey of 90 visualisation aithors and semi*structured inverviews with 13 infuential professional visualisation designers and journalists (do not self identify as researchers).  \n* stopped aggrssively recruiting new participants once resonses conveged on a set of widely held rationals. \n* between December 2018 and may 2019. \n* shared survey link on twitter and went into draw for $50 amazon gift card.  \n\n\n\n#### Reasons to not visualise\n* Frequently cited reasons\n  + 62% (53/85) dont want to confuse or overwhelm viewers\n  + 47% (40/85) dont have access to uncertainty information\n  + 26% (22/85) not knowing how to calculate uncertainty\n  + 17% (15/85) dont want to make data seem questionable\n* visualisations are both conveying and producing a signal which is validated by the authors analysis but obfuscated by exposing uncertainty\n* belief that a visualisation that explicity represented uncertainty requires more effort than a visualisation without it was implicit in many comments\n  + handful of survey respondents mentioned time and other constraints directly.\n  + stakeholders did not want to pay for a propper visualisation\n* Uncertainty obfuscates signal\n  + uncertainty is viewed as separate or even \"tengential\" to visualised information.\n  + a view of uncertinty questioning the message or signal came up or was confirmed in nearly every interview. \n  + either seen as obfuscating a signal because \"error could be so large that it invalidates the data\"\n  + or it is seen as distracting\n  + Or offers a crack in the visualisation \"how did you get these numbers\". Many authors were motivated to avoid this question entirely.\n  + Percieved to undermind authors credibility\n* Uncertainty may be percieved as misplaced prescition \n  + \"there's uncertainty baout uncertainty, so if I put a number on it, what if Im wrong?\" (I wonder if there are concerns about being blamed for an outcome outside the uncertainty intervals)\n* Authors found it difficult to calculate and describe uncertainty or the model assumptions used to derive it\n* Faith in process among authors was one of the most common rationals among authors for why omitting uncertainty information was acceptable \n  + \"data experts would make sure things are significant\"\n  + implies truth of signal is independent of the visualisation, which simply expresses the signal, although more than half of interviewees mentioned ways in which they used the visualisation process to identify and clarify the signal.\n* Faith in Process among viewers\n  + similar to above to it implies they dont have to give uncertainty or information about the process to trust that a signal is valid.\n\n#### Adjacent info\n* most through of uncertainty as an interval range or region, or possible outs and/or the possibility that plotted values may not represent real values\n* 76% of authors had depicted uncertainty in a visualisation in the past year\n* nearly 20% of authors did not recll communicating uncertainty at all in the last year\n* however it was a rare occurence, only a quater of respondents described communicating uncertainty in 50% or more of their visualisations\n* 62% had used text to warn their viewers of the potential for uncertainty in results\n* 5% of survey respondents described uncertainty as variance\n* nearly 50% of respondents admitted to having intended or attempted to communicate uncertainty in a visualisation within the prior year but had ultimately not included it. roughly 33% of interviewees described instances where uncertainty info was calculated but ultimately not unfluced\n* majority of the surveyed authors expressed a belief that uncertainty should be visualised more than it currently is. Due to responsibility of accurate presentations, omitting information is misleading/lying, percieved uncertainty representations to have educational potential * \"otherwise people wont get better at realizing nuances in the data\"\n* observed some form of inconsistency between the implied desire for more uncertainty and the interviewees statements about sufficiend or ideal practices for uncertainty.\n* Authors who seemed capable of calculating and representing uncertainty well, who occupy roles in which they have the freedom to experiemnt and who express interest in representing uncertainty more often seemed unable to produce self\n* satifying reasons for they they did not represent uncertainty more often\n* Worth nothing that many authors seemed confidence in stating rationals as though they perceived them to be truths that do not require examples to demonstrate.\n  + it is possible that rationals for omission represent ingrained beliefs more than conclusions authors have drawn from concrete experiences attempting to convey uncertainty.\n\n### The Lure of Incredible Certitude\nReference: @Manski2020\n* Starts off by listing examples of incredible certitude in many fields (such as economics, medicine, law) to show it is a prevalent issue\n* The rationals for incredible certitude section is mostly annecdotal but I suspect people use annecdotal edidence to justify their choices in their day to day life (which is what we care about)\n\nCitations from Hullman paper\n* belief non*expert audiences will not understand uncertainty information\n* presenting will make message seem less credible\n* not presenting uncertainty info will simplify decision making\n* beleif people cannot tollerate uncertainty\n* belief uncertainty creates negative feelings\n* belief not presenting uncertainty makes it easier to coordinate beliefs\n\n### Communicating Uncertainty, Fulfilling the Duty to Inform\n* experts see uncertainty as misplaced imprecision\n* experts do not expert uncertainties to be understood\n* experts anticipate being criticized for communicating uncertainty\n* experts do not know how to express their uncertainties\n\nCitations from Hullman paper\n* fear uncertainty imply unwarranted precision in estimates\n* thinking that the presence of uncertainty is common knowledge\n* belief non-expert audiences will not understand uncertainty information\n* presenting will make message seem less credible\n\n\n### Others\n\n[4] Uncertainty visualisation: why might it fail?\n* authors see uncertainty metadata as no different from othe rmetadata and include it only as secondary\n* many struggle to find representations that are compativle with data, tasks, and organizational goals\n* find it difficult to evaluate the inpact of uncertainty on visualisation based judgements.\n\n[30] In pursuit of error: a survey of uncertainty visualisation evaluation\n* find it difficult to evaluate the impact of uncertainty on visualisation based judgements.\n\n\n[15] Verbal versus numerical probabilities: Efficiency, biases, and the preference paradox\n[46] Patterns of preference for numerical and verbal probabilities.\n* experts or analysists typically prefer to communicate uncertainty in qualitative terms, fearing misinterpretations. Descision makers prefer uncertainty in precise quantitative terms.\n\n[22] Knowing with certainty: The appropriateness of extreme confidence. Journal\n[21] Subjective confidence in forecasts.\n[38] Calibration of probabilities: The state of the art to 1980\n* People are overconfidence when presented with uncertainty info\n\n[17] Utilizing graphical formats to convey un* certainty in a decision*making task\n[42] Communicating uncertainty in official economic statistics: an appraisal fifty years after morgenstern.\n* omitting uncertainty unformation may result from an unstated norm\n\n[5] How data work* ers cope with uncertainty: A task characterisation study.\n[33] Decision*making under uncertainty in research synthesis: Designing for the garden of forking paths. 2019.\n[51] Revealing uncer* tainty for information visualization.\n* data workers precieve a tension between transparancy and decision makers desire for simplictiy\n\n[31] Hypothetical outcome plots outper* form error bars and violin plots for inferences about reliability of variable ordering\n[34] Hypothetical outcome plots help untrained observers judge trends in ambiguous data. IEEE\n[16] Uncertainty displays using quantile dotplots or cdfs improve transit decision*making.\n[35] When (ish) is my bus?: Usercentered visualizations of uncertainty in everyday, mobile predictive systems.\n[10] Value suppressing uncertainty palettes. In\n[9] Error bars considered harmful: Exploring alternate encodings for mean and error\n* studies evaluate visualisations intended fro non*experts as well as experts\n\n## Reasons Against\n* Graphical representations improve peoples ability to translate outcomes to a probability distribution. Reports of variance, mean, etc were more accurate when participants were asked to draw the distribution rather than report single statistics. (@Goldstein2014)\n\n* People presented cancer risks had more ambiguity aversion when presented with a range rather than a point estimate (@Han2009)\n\n* They get a bunch of people to adjust error bars until the two means are \"just\" statistically significantly different. Most people think this is when they are not overlapping but that actually gives a p value much less than 0.05. People also dont know the difference between confidence intervals and SE bars.(@Bella2005)\n\n* Researchers and students somewhat misinterpret confidence intervals. Some misunderstandings are bigger than others and they are pretty stern on interpreting the CI as a frequentist. I.e. \"We can be 95% confident that the true mean lies between 0.1 and 0.4\" is incorrect, and only \"if we were to repeat the experiment over and over again, then 95% of the time the confidence interval contains the true mean\". (@Hoekstra2014)\n\n* This paper has SEVERAL interesting findings. 1) dot plots slay again, 2) the better understanding of probabilities translates to better descisions, 3) people get better at making decisions where they incorperate the uncertainty over time. (@Fernandes2018)\n\n* This is a study investigating how to communicate uncertainty quickly on a small screen (mobile) to the general public. The specific case scenario is communicating bus arrival times.(@Kay2016)",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}