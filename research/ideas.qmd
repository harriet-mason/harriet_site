---
title: "Research Ideas"
editor: visual
---

# Experiments
## Why People don't Visualise

## Unplaced comments

-   Additionally, a well done uncertainty visualisation can also give be
    used to convey adjacent information. In forecasting the uncertinty
    visualisation adds to the plot, i.e. it lets you know what is data
    and what is a forecast from a model, I suspect it is frequently done
    in this area for this reason.
-   estimates do not require as much thinking as uncertainty. You may
    assume a normal distribution and identical appearance between your
    sample and forecst implicitly when you do an estimate, but you make
    these things explicit when you present uncertainty. I wonder if
    people are unaware that they are making these assumptions when they
    produce estimates.
-   People draw an uncertainty bound around data that does not have any
    uncertainty expression if they are aware that it is only an
    estimate. In the absence of any uncertainty estimates it would be
    interesting to see where people naturally draw their uncertainty
    bounds (if they are at a level of significance) and what impacts
    them.
-   This reminds me of unbiassed vs consistent estimators. Even the
    estimators themselves have been selected on the principal that a low
    variance is better than a high variance reguardless of the point
    prediction.
-   Think of how to test assertions vs rebuttals -- Ask people (maybe
    done) when someone uses uncertainty what do you think of (what does
    it mean) -- Is there uncertainty in this plot (what is it) if none
    what would be an addition to the plot to convey it
-   I wonder if I visualise uncertainty in forecasting models more
    because 1) the model gives a clear divide of no uncertainty (in the
    data) and the uncertainty (in the model). Also it is the default. --
    software developers should include uncertainty as a default
-   Danger of using visualisation to determine signal strength (without
    uncertainty) in that LDA paper
-   The secondary nature of the uncertainty aspect of models and
    estimates is evidenced by the fact that they are not as immediately
    and widely available as measures of central tendancy.
-   I think the issue of "fraud" and "people don't understand
    uncertainty" are actually connected. There are many incentives to
    represent work as more certain than it is. For every single instance
    where a point prediction is appropriate, a range could also suffice.
    They are similar in the amount of information to process, but people
    opt for a point rather than a range. In some instances it might be
    confusing to give a range (like temperature) but
-   incentivise visualising uncertainty. Make the best and easiest to
    understand visualisation the one that includes uncertainty. The
    forecast plot makes it clear where the data ends and the forecast
    starts, adding additional information that is adjacent to the
    uncertainty and gives a second incentive for visualising the
    uncertainty.
-   Saying "it will happen" vs "it has a 10% chance of happening" is not
    only for not trusting the audience, it is more about speaking to
    individual vs group. If you speak to a large enough number of
    people, the uncertainy disappears. It is not "you have a 10% chance
    of getting cancer" and becomes "10 of you will get cancer".
-   I wonder if the visualisations have the same issue as electoral
    systems. If an electoral system is too simple, highly educated
    people don't vote because they don't respect the process, if it is
    too complicated, poorly educated people don't vote because they
    don't understand it. Making an electoral system is a constant
    ballancing act between these two forces and I think making a good
    visualisation is the same.
-   Better communication aroud the estimates themsevles. "nobody
    experiences the average"
-   James Goldie: uncertainty is confusing to audiences so it is
    skipped. instead we select cases where the pattern is clear and
    discuss uncertainty only if it is relevant.
-   Casey Briggs: we provide trend forecasts instead of predictions
    because we dont convey uncertainty
-   Liam Mannix: Predictions that don't come true make the public lose
    confidence.
-   Michael Lyndmore: From my experience, policy makers hate
    uncertainty, so it is taken out.

